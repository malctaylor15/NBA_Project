lines(xfit, yfit, col=color, lwd=2)
}
makeHist(dist)
?dchisq
median(dist)
makeHist <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 0.5)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 0.5)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 0.55073)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 0.7)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 0.1)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 0.8)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 1)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = 2)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
makeHistChi <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = .9)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist)
var(dist)
mean(dist)
makeHist <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHist(dist)
makeHistChi(dist, df1 = mean(dist))
makeHistChi <- function(x, df1, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = df1)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHistChi(dist, df1 = mean(dist))
makeHistChi(dist, df1 = 0.5507)
sd(dist)^2
makeHistChi(dist, df1 = (sd(dist))^2)
makeHistChi(dist, df1 = 0.99)
makeHistChi(dist, df1 = 1)
makeHistChi(dist, df1 = 1.5)
makeHistChi(dist, df1 = 1)
?seq
dnorm(dist, 1)
chi_1 <- dnorm(dist, 1)
makeHistChi(dist, df1 = 1)
hist(results[,1], breaks = 40)
dist <- results[,21] - results[,1]
hist(dist)
r <- dist+0.5
hist(dist)
hist(r)
quantile(dist, c(0.05,0.95))
hist(dist)
ecdf(dist)(0)
setwd("~/Spring 2016/Data Analysis/HW3")
library(mvtnorm)
vix1<-read.csv("VIX-weekly-26yr.csv")
vixdates<-as.Date(vix1$Date,"%m/%d/%y")
numb_obs <- 200
nsim  <-50000
distibution_func <- function(vix, numb_obs, nsim ){
# Create Log Returns
vixw<-vix$VIX[1:numb_obs]
lv<-log(vixw/100)
# Prepare linear regression parts
TT<-numb_obs - 3
xmat  <-cbind(rep(1,TT),lv[3:(numb_obs-1)],lv[2:(numb_obs-2)],lv[1:(numb_obs-3)])
bhat  <-xpxinv%*%t(xmat)%*%lv[4:numb_obs]
resid <-lv[4:numb_obs]-fitted
nureg <- TT - 4
fitted<-xmat%*%bhat
xpxinv<-solve(t(xmat)%*%xmat)
nusq  <- sum(resid^2)
# Start the Monte Carlo Simulation
sigdraws<-sqrt(nusq/rchisq(nsim,nureg))    # Draw all the sigmas
bdraws <-rmvnorm(nsim,sigma=xpxinv)  # Draw the betas with the
bdraws <-bdraws*sigdraws+rep(bhat,each=nsim)
efdraws <- rnorm(nsim,mean=0,sd=1) # Draw the noise?
efdraws <- efdraws * sigdraws  	# Same trick, as for betas
lvf     <- matrix(0,ncol=3,nrow=nsim)	# draws of lv
lvf[,1] <- bdraws %*% c(1,lv[numb_obs],lv[(numb_obs-1)],lv[(numb_obs-2)]) + efdraws[,1]
evix <-exp(lvf) 	# Make the draws of vix itself
# See where real values fall on empirical distribution
emp1 <- ecdf(evix[,1])(vix$VIX[(numb_obs+1)]/100)
quant1 <- quantile(evix[,1], c(0.05,0.25,0.5,0.75,0.95))
mean1 <- mean(evix)
final_return <- c(emp1, quant1, mean1)
return(final_return)
}
# Pre allocate
results <- data.frame(matrix(0,ncol = 21, nrow = 1188))
i <-1
dataset <- vix1[i:(numb_obs+2+i),]
results[i,] <- distibution_func(dataset, numb_obs, nsim)
results[i,] <- distibution_func(dataset, numb_obs, nsim)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/Spring 2016/Data Analysis/HW3/backtest_practice_more.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
View(results)
distibution_func <- function(vix, numb_obs, nsim ){
# Create Log Returns
vixw<-vix$VIX[1:numb_obs]
lv<-log(vixw/100)
# Prepare linear regression parts
TT<-numb_obs - 3
xmat  <-cbind(rep(1,TT),lv[3:(numb_obs-1)],lv[2:(numb_obs-2)],lv[1:(numb_obs-3)])
xpxinv<-solve(t(xmat)%*%xmat)
bhat  <-xpxinv%*%t(xmat)%*%lv[4:numb_obs]
fitted<-xmat%*%bhat
resid <-lv[4:numb_obs]-fitted
nureg <- TT - 4
nusq  <- sum(resid^2)
# Start the Monte Carlo Simulation
sigdraws<-sqrt(nusq/rchisq(nsim,nureg))    # Draw all the sigmas
bdraws <-rmvnorm(nsim,sigma=xpxinv)  # Draw the betas with the
bdraws <-bdraws*sigdraws+rep(bhat,each=nsim)
efdraws <- rnorm(nsim,mean=0,sd=1) # Draw the noise?
efdraws <- efdraws * sigdraws  	# Same trick, as for betas
lvf     <- matrix(0,ncol=3,nrow=nsim)	# draws of lv
lvf[,1] <- bdraws %*% c(1,lv[numb_obs],lv[(numb_obs-1)],lv[(numb_obs-2)]) + efdraws
evix <-exp(lvf) 	# Make the draws of vix itself
# See where real values fall on empirical distribution
emp1 <- ecdf(evix[,1])(vix$VIX[(numb_obs+1)]/100)
quant1 <- quantile(evix[,1], c(0.05,0.25,0.5,0.75,0.95))
mean1 <- mean(evix)
final_return <- c(emp1, quant1, mean1)
return(final_return)
}
results <- data.frame(matrix(0,ncol = 21, nrow = 1188))
results <- data.frame(matrix(0,ncol = 7, nrow = 1188))
dataset <- vix1[i:(numb_obs+2+i),]
results[i,] <- distibution_func(dataset, numb_obs, nsim)
View(results)
distibution_func(dataset, numb_obs, nsim)
results[i,] <- distibution_func(dataset, numb_obs, nsim)
View(results)
# Trading Strategy
setwd("~/Spring 2016/Data Analysis/HW3")
library(mvtnorm)
vix1<-read.csv("VIX-weekly-26yr.csv")
vixdates<-as.Date(vix1$Date,"%m/%d/%y")
numb_obs <- 200
nsim  <-50000
distibution_func <- function(vix, numb_obs, nsim ){
# Create Log Returns
vixw<-vix$VIX[1:numb_obs]
lv<-log(vixw/100)
# Prepare linear regression parts
TT<-numb_obs - 3
xmat  <-cbind(rep(1,TT),lv[3:(numb_obs-1)],lv[2:(numb_obs-2)],lv[1:(numb_obs-3)])
xpxinv<-solve(t(xmat)%*%xmat)
bhat  <-xpxinv%*%t(xmat)%*%lv[4:numb_obs]
fitted<-xmat%*%bhat
resid <-lv[4:numb_obs]-fitted
nureg <- TT - 4
nusq  <- sum(resid^2)
# Start the Monte Carlo Simulation
sigdraws<-sqrt(nusq/rchisq(nsim,nureg))    # Draw all the sigmas
bdraws <-rmvnorm(nsim,sigma=xpxinv)  # Draw the betas with the
bdraws <-bdraws*sigdraws+rep(bhat,each=nsim)
efdraws <- rnorm(nsim,mean=0,sd=1) # Draw the noise?
efdraws <- efdraws * sigdraws  	# Same trick, as for betas
lvf     <- matrix(0,ncol=3,nrow=nsim)	# draws of lv
lvf[,1] <- bdraws %*% c(1,lv[numb_obs],lv[(numb_obs-1)],lv[(numb_obs-2)]) + efdraws
evix <-exp(lvf) 	# Make the draws of vix itself
# See where real values fall on empirical distribution
emp1 <- ecdf(evix[,1])(vix$VIX[(numb_obs+1)]/100)
quant1 <- quantile(evix[,1], c(0.05,0.25,0.5,0.75,0.95))
mean1 <- mean(evix)
final_return <- c(emp1, quant1, mean1)
return(final_return)
}
# Pre allocate
results <- data.frame(matrix(0,ncol = 7, nrow = 1188))
for (i in 1:1188){
dataset <- vix1[i:(numb_obs+2+i),]
results[i,] <- distibution_func(dataset, numb_obs, nsim)
}
# Trading Strategy
setwd("~/Spring 2016/Data Analysis/HW3")
library(mvtnorm)
vix1<-read.csv("VIX-weekly-26yr.csv")
vixdates<-as.Date(vix1$Date,"%m/%d/%y")
numb_obs <- 200
nsim  <-50000
# Create Log Returns
vixw<-vix$VIX[1:numb_obs]
lv<-log(vixw/100)
# Prepare linear regression parts
TT<-numb_obs - 3
xmat  <-cbind(rep(1,TT),lv[3:(numb_obs-1)],lv[2:(numb_obs-2)],lv[1:(numb_obs-3)])
xpxinv<-solve(t(xmat)%*%xmat)
bhat  <-xpxinv%*%t(xmat)%*%lv[4:numb_obs]
fitted<-xmat%*%bhat
resid <-lv[4:numb_obs]-fitted
nureg <- TT - 4
nusq  <- sum(resid^2)
# Start the Monte Carlo Simulation
sigdraws<-sqrt(nusq/rchisq(nsim,nureg))    # Draw all the sigmas
bdraws <-rmvnorm(nsim,sigma=xpxinv)  # Draw the betas with the
bdraws <-bdraws*sigdraws+rep(bhat,each=nsim)
efdraws <- rnorm(nsim,mean=0,sd=1) # Draw the noise?
efdraws <- efdraws * sigdraws  	# Same trick, as for betas
lvf     <- matrix(0,ncol=3,nrow=nsim)	# draws of lv
lvf[,1] <- bdraws %*% c(1,lv[numb_obs],lv[(numb_obs-1)],lv[(numb_obs-2)]) + efdraws
evix <-exp(lvf) 	# Make the draws of vix itself
distibution_func <- function(vix, numb_obs, nsim ){
# See where real values fall on empirical distribution
emp1 <- ecdf(evix[,1])(vix$VIX[(numb_obs+1)]/100)
}
# Trading Strategy
setwd("~/Spring 2016/Data Analysis/HW3")
library(mvtnorm)
vix1<-read.csv("VIX-weekly-26yr.csv")
vixdates<-as.Date(vix1$Date,"%m/%d/%y")
numb_obs <- 200
nsim  <-50000
# Create Log Returns
vixw<-vix$VIX[1:numb_obs]
lv<-log(vixw/100)
distibution_func <- function(vix, numb_obs, nsim ){
# Prepare linear regression parts
TT<-numb_obs - 3
xmat  <-cbind(rep(1,TT),lv[3:(numb_obs-1)],lv[2:(numb_obs-2)],lv[1:(numb_obs-3)])
xpxinv<-solve(t(xmat)%*%xmat)
bhat  <-xpxinv%*%t(xmat)%*%lv[4:numb_obs]
fitted<-xmat%*%bhat
resid <-lv[4:numb_obs]-fitted
nureg <- TT - 4
nusq  <- sum(resid^2)
# Start the Monte Carlo Simulation
sigdraws<-sqrt(nusq/rchisq(nsim,nureg))    # Draw all the sigmas
bdraws <-rmvnorm(nsim,sigma=xpxinv)  # Draw the betas with the
bdraws <-bdraws*sigdraws+rep(bhat,each=nsim)
efdraws <- rnorm(nsim,mean=0,sd=1) # Draw the noise?
efdraws <- efdraws * sigdraws  	# Same trick, as for betas
lvf     <- matrix(0,ncol=3,nrow=nsim)	# draws of lv
lvf[,1] <- bdraws %*% c(1,lv[numb_obs],lv[(numb_obs-1)],lv[(numb_obs-2)]) + efdraws
evix <-exp(lvf) 	# Make the draws of vix itself
# See where real values fall on empirical distribution
emp1 <- ecdf(evix[,1])(vix$VIX[(numb_obs+1)]/100)
quant1 <- quantile(evix[,1], c(0.05,0.25,0.5,0.75,0.95))
mean1 <- mean(evix)
final_return <- c(emp1, quant1, mean1)
return(final_return)
}
# Pre allocate
setwd("~/Spring 2016/Data Analysis/HW3")
library(mvtnorm)
vix1<-read.csv("VIX-weekly-26yr.csv")
vixdates<-as.Date(vix1$Date,"%m/%d/%y")
numb_obs <- 200
nsim  <-50000
distibution_func <- function(vix, numb_obs, nsim ){
# Create Log Returns
vixw<-vix$VIX[1:numb_obs]
lv<-log(vixw/100)
# Prepare linear regression parts
TT<-numb_obs - 3
xmat  <-cbind(rep(1,TT),lv[3:(numb_obs-1)],lv[2:(numb_obs-2)],lv[1:(numb_obs-3)])
xpxinv<-solve(t(xmat)%*%xmat)
bhat  <-xpxinv%*%t(xmat)%*%lv[4:numb_obs]
fitted<-xmat%*%bhat
resid <-lv[4:numb_obs]-fitted
nusq  <- sum(resid^2)
# Start the Monte Carlo Simulation
sigdraws<-sqrt(nusq/rchisq(nsim,nureg))    # Draw all the sigmas
bdraws <-rmvnorm(nsim,sigma=xpxinv)  # Draw the betas with the
bdraws <-bdraws*sigdraws+rep(bhat,each=nsim)
efdraws <- rnorm(nsim,mean=0,sd=1) # Draw the noise?
nureg <- TT - 4
efdraws <- efdraws * sigdraws  	# Same trick, as for betas
lvf     <- matrix(0,ncol=3,nrow=nsim)	# draws of lv
lvf[,1] <- bdraws %*% c(1,lv[numb_obs],lv[(numb_obs-1)],lv[(numb_obs-2)]) + efdraws
evix <-exp(lvf) 	# Make the draws of vix itself
# See where real values fall on empirical distribution
emp1 <- ecdf(evix[,1])(vix$VIX[(numb_obs+1)]/100)
quant1 <- quantile(evix[,1], c(0.05,0.25,0.5,0.75,0.95))
mean1 <- mean(evix)
final_return <- c(emp1, quant1, mean1)
return(final_return)
}
# Pre allocate
results <- data.frame(matrix(0,ncol = 7, nrow = 1188))
for (i in 1:1188){
dataset <- vix1[i:(numb_obs+2+i),]
results[i,] <- distibution_func(dataset, numb_obs, nsim)
}
hist(results[,1], breaks = 40)
vixdates1 <- vixdates[204:1391]
plot(vixdates1, results[,2])
plot(vixdates1, results[,1])
names(results)[c(1,7)] <- c("Empirical location", "Mean")
View(results)
names(results)[c(1,4,7)] <- c("Empirical location","Median", "Mean")
dist1 <- results[,21] - results[,1]
hist(dist1)
dist1 <- results[,7] - results[,1]
hist(dist1)
hist(dist1, breaks = 40)
dist <- dist1^2
hist(dist, breaks= 40)
makeHist <- function(x, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
makeHist(dist)
makeHistChi <- function(x, df1, color = "blue", title = "Histogram"){
h<-hist(x,main=title, breaks = 40)
xfit<-seq(min(x),max(x),length=40)
yfit<-dchisq(xfit,df = df1)
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col=color, lwd=2)
}
# Fit Chi Sq distribution to data, not sure how to pick k
# Check wiki and try different things
# Try the mean = k
makeHistChi(dist, df1 = mean(dist))
# Try the variance
makeHistChi(dist, df1 = (sd(dist))^2)
# Try equation for median = f(k)
# Found solution on wolfram = 0.5507
makeHistChi(dist, df1 = 0.5507)
# Next Step- add chi sq goodness of fit
hist(dist1, breaks = 40)
hist(results[,1], breaks = 40)
hist(results[,1], breaks = 40)
vixdates1 <- vixdates[204:1391]
plot(vixdates1, results[,1])
dist1 <- results[,7] - results[,1]
hist(dist1, breaks = 40)
ecdf(dist1)(0)
ecdf(dist)(0)
ecdf(dist1)(0)
plot(vixdates1, dist1)
plot(vixdates1, dist)
setwd("C:/Users/board/Desktop/Kaggle/NBA_Project")
library(moments)
library(Quandl)
library(lubridate)
library(pls)
set.seed(2)
data <- read.csv("Curry2015-2016stats_clean2.csv")
# Data Cleaning
data$Date <- as.Date(data$Date)
data$SecondsPlayed <- hms(data$MP)
data$SecondsPlayed <- 60*hour(data$SecondsPlayed) + minute(data$SecondsPlayed)
data$MP <- NULL
# There are some missing values where he doesn't shoot free throws for his FT %
sum(is.na(data))
# Impute mean for free throw percentage
data$FT.[is.na(data$FT.)] = mean(data$FT., na.rm=TRUE)
# Look at the data
head(data)
tail(data)
pairs(data)
# Function for transforming financial data
fin_data_transform <- function(tickerData){
numb_returns <- dim(tickerData)[1]
#Pre allocate space
transformed_df <- data.frame(matrix(nrow = (numb_returns-1),ncol = 3))
# Place date into data frame
transformed_df[,1] <- tickerData[-1,1]
# Over night effect on stock price
for(i in 1:(numb_returns-1)){
transformed_df[i,2] <- (tickerData$Open[i+1]-tickerData$Close[i])/tickerData$Open[i+1]
}
# Calculate log returns
transformed_df[,3] <- log1p(transformed_df[,2])
names(transformed_df)[1:3] <- c("Date","Overnight_Returns", "Log_Overnight_Returns")
return (transformed_df)
}
# Import the financial data and calculate log returns
UA_in_sample <- Quandl("YAHOO/UA", start_date = "2015-10-27 ", end_date = "2016-04-13")
numb_returns <- dim(UA_in_sample)[1]
UA_in_return <- fin_data_transform(UA_in_sample)
# Dates that have both stock return and game
similar_dates <- as.Date(UA_in_return$Date[UA_in_return$Date %in% data$Date],format = '%m-%d-%Y')
numb_both <- length(similar_dates)
# Create testing dataframe
data1 <- data[data$Date %in% UA_in_return$Date ,]
data1$UA_LogReturns <- UA_in_return$Log_Overnight_Returns[UA_in_return$Date %in% data$Date]
data1$Date <- NULL
# Peak at new data frame
head(data1)
tail(data1)
# Linear Regression and analysis
fit1 <- lm(UA_LogReturns ~., data= data1)
summary(fit1)
plot(fit1)
prince <- prcomp(data1, center = TRUE, scale = TRUE)
summary(prince)
plot(prince)
# Principal Components Regression
# ISLR 256
pcr.fit <- pcr(UA_LogReturns ~., data =data1,scale = TRUE, validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
# Smallest error at 11 components
# Try adding XLF ETF
XLF_in_sample <- Quandl("GOOG/NYSE_XLF", start_date = "2015-10-27 ", end_date = "2016-04-13")
?step
## install.packages("boot")
library(haven)
library(boot)
library(haven)
install.packages("boot")
install.packages("boot")
install.packages("haven")
library(haven)
library(boot)
# Remember to change directory to where the file is
smoking <- read_dta("C:/Users/board/Documents/GitHub/Statistics-420-Fall-2015/Smoking Predictors Project/Smoking.dta")
## Number of observations
n = length(smoking$smoker)
## Vector that will contain the CV estimates
CV_est = rep(1,6)
## Fit Basic Model with the predictors
basic_fit <- glm(smoker~., family = "binomial", data = smoking)
summary(basic_fit)
## Converts the Betas from log odds to probability
round((exp(basic_fit$coefficients)/(1+exp(basic_fit$coefficients))),4)
## Cross Validation for Huge Model
CV_est[1] <- cv.glm(smoking,basic_fit, K=10)$delta[1]
## Narrow Basic Model with backward BIC
mod_basic <- step(basic_fit,direction = "backward", trace = 0, k = log(n))
summary(mod_basic)
## Converts the Betas from log odds to probability
round((exp(mod_basic$coefficients)/(1+exp(mod_basic$coefficients))),4)
## Cross Validation for Modified Basic Model
CV_est[2] <- cv.glm(smoking, mod_basic, K=10)$delta[1]
##__ Repeat this process for the three models (huge and basic-education)
## Huge Model with all of the interaction terms
huge_fit <- glm(smoker~.*., family = "binomial", data = smoking)
summary(huge_fit)
length(huge_fit$coefficients)
summary(huge_fit)
## Converts the Betas from log odds to probability
round((exp(huge_fit$coefficients)/(1+exp(huge_fit$coefficients))),4)
## Cross Validation for Huge Model
CV_est[3] <- cv.glm(smoking,huge_fit, K=10)$delta[1]
## Narrow Huge Model with backward BIC
mod_huge <- step(huge_fit,direction = "backward", trace = 0, k = log(n))
summary(mod_huge)
## Converts the Betas from log odds to probability
round((exp(mod_huge$coefficients)/(1+exp(mod_huge$coefficients))),4)
## Cross Validation for Modified Huge Model
